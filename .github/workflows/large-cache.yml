name: Cache Large Files Workflow

on:
  workflow_dispatch:

jobs:
  generate-cache:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-22.04, ubuntu-22.04-ppc64le]

    steps:
      # Step 1: Generate large dummy files with random data
      - name: Generate Large Dummy Files (Non-Compressible)
        run: |
          mkdir -p cache_data
          echo "Generating a 1GB random data file on ${{ matrix.os }}..."
          dd if=/dev/urandom of=cache_data/random_file_1GB bs=1M count=1024
          echo "Generating another 1GB random data file on ${{ matrix.os }}..."
          dd if=/dev/urandom of=cache_data/random_file_2GB bs=1M count=1024
          echo "Generated 2GB of random data files on ${{ matrix.os }}."

      # Step 2: Cache the large files with a single unique key
      - name: Cache Large Files
        uses: actions/cache@v4
        with:
          path: cache_data
          key: large-file-cache-${{ matrix.os }}-${{ github.sha }}-${{ github.ref }}-${{ github.run_id }}

      # Step 3: Confirm the cache is stored
      - name: List Cached Files
        run: ls -lh cache_data
